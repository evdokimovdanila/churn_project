{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fae4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, cv ,Pool\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer,KNNImputer\n",
    "import hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed0359",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c42677",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/orange_small_churn_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b43761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  ...   Var222  \\\n",
       "0   0   NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN   NaN  ...  vr93T2a   \n",
       "1   1   NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN   NaN  ...  6hQ9lNX   \n",
       "2   2   NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN   NaN  ...  catzS2D   \n",
       "3   3   NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN   NaN  ...  e4lqvY0   \n",
       "4   4   NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN   NaN  ...  MAz3HNj   \n",
       "\n",
       "       Var223  Var224  Var225  Var226   Var227         Var228  Var229  Var230  \\\n",
       "0  LM8l689qOp     NaN     NaN    fKCe  02N6s8f  xwM2aC7IdeMC0     NaN     NaN   \n",
       "1  LM8l689qOp     NaN    ELof    xb3V     RAYp        55YFVY9    mj86     NaN   \n",
       "2  LM8l689qOp     NaN     NaN    FSa2     ZI9m  ib5G6X1eUxUn6    mj86     NaN   \n",
       "3  LM8l689qOp     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I     NaN     NaN   \n",
       "4  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I     NaN     NaN   \n",
       "\n",
       "   labels  \n",
       "0    -1.0  \n",
       "1    -1.0  \n",
       "2    -1.0  \n",
       "3     1.0  \n",
       "4    -1.0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92561aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18299 entries, 0 to 18298\n",
      "Columns: 232 entries, ID to labels\n",
      "dtypes: float64(192), int64(2), object(38)\n",
      "memory usage: 32.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d3da0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'Var1': 18038,\n",
       " 'Var2': 17831,\n",
       " 'Var3': 17832,\n",
       " 'Var4': 17736,\n",
       " 'Var5': 17799,\n",
       " 'Var6': 1991,\n",
       " 'Var7': 1976,\n",
       " 'Var8': 18299,\n",
       " 'Var9': 18038,\n",
       " 'Var10': 17799,\n",
       " 'Var11': 17832,\n",
       " 'Var12': 18085,\n",
       " 'Var13': 1976,\n",
       " 'Var14': 17832,\n",
       " 'Var15': 18299,\n",
       " 'Var16': 17799,\n",
       " 'Var17': 17736,\n",
       " 'Var18': 17736,\n",
       " 'Var19': 17736,\n",
       " 'Var20': 18299,\n",
       " 'Var21': 1991,\n",
       " 'Var22': 1792,\n",
       " 'Var23': 17799,\n",
       " 'Var24': 2616,\n",
       " 'Var25': 1792,\n",
       " 'Var26': 17799,\n",
       " 'Var27': 17799,\n",
       " 'Var28': 1793,\n",
       " 'Var29': 18038,\n",
       " 'Var30': 18038,\n",
       " 'Var31': 18299,\n",
       " 'Var32': 18299,\n",
       " 'Var33': 18010,\n",
       " 'Var34': 17831,\n",
       " 'Var35': 1792,\n",
       " 'Var36': 17831,\n",
       " 'Var37': 17736,\n",
       " 'Var38': 1792,\n",
       " 'Var39': 18299,\n",
       " 'Var40': 17831,\n",
       " 'Var41': 18038,\n",
       " 'Var42': 18299,\n",
       " 'Var43': 17831,\n",
       " 'Var44': 1792,\n",
       " 'Var45': 18171,\n",
       " 'Var46': 17831,\n",
       " 'Var47': 18038,\n",
       " 'Var48': 18299,\n",
       " 'Var49': 17831,\n",
       " 'Var50': 18038,\n",
       " 'Var51': 16888,\n",
       " 'Var52': 18299,\n",
       " 'Var53': 18038,\n",
       " 'Var54': 17831,\n",
       " 'Var55': 18299,\n",
       " 'Var56': 18055,\n",
       " 'Var57': 0,\n",
       " 'Var58': 18038,\n",
       " 'Var59': 17990,\n",
       " 'Var60': 17799,\n",
       " 'Var61': 18010,\n",
       " 'Var62': 18085,\n",
       " 'Var63': 18041,\n",
       " 'Var64': 18215,\n",
       " 'Var65': 1976,\n",
       " 'Var66': 18041,\n",
       " 'Var67': 17799,\n",
       " 'Var68': 17831,\n",
       " 'Var69': 17799,\n",
       " 'Var70': 17799,\n",
       " 'Var71': 17911,\n",
       " 'Var72': 8163,\n",
       " 'Var73': 0,\n",
       " 'Var74': 1976,\n",
       " 'Var75': 17831,\n",
       " 'Var76': 1792,\n",
       " 'Var77': 18038,\n",
       " 'Var78': 1792,\n",
       " 'Var79': 18299,\n",
       " 'Var80': 17799,\n",
       " 'Var81': 1991,\n",
       " 'Var82': 17736,\n",
       " 'Var83': 1792,\n",
       " 'Var84': 17832,\n",
       " 'Var85': 1792,\n",
       " 'Var86': 18038,\n",
       " 'Var87': 18038,\n",
       " 'Var88': 17922,\n",
       " 'Var89': 18055,\n",
       " 'Var90': 18038,\n",
       " 'Var91': 17911,\n",
       " 'Var92': 18247,\n",
       " 'Var93': 17799,\n",
       " 'Var94': 8163,\n",
       " 'Var95': 17831,\n",
       " 'Var96': 17831,\n",
       " 'Var97': 17799,\n",
       " 'Var98': 18085,\n",
       " 'Var99': 17736,\n",
       " 'Var100': 18038,\n",
       " 'Var101': 18009,\n",
       " 'Var102': 18157,\n",
       " 'Var103': 17799,\n",
       " 'Var104': 17990,\n",
       " 'Var105': 17990,\n",
       " 'Var106': 17736,\n",
       " 'Var107': 17799,\n",
       " 'Var108': 18038,\n",
       " 'Var109': 2616,\n",
       " 'Var110': 18038,\n",
       " 'Var111': 17911,\n",
       " 'Var112': 1792,\n",
       " 'Var113': 0,\n",
       " 'Var114': 17831,\n",
       " 'Var115': 17990,\n",
       " 'Var116': 18038,\n",
       " 'Var117': 17736,\n",
       " 'Var118': 18247,\n",
       " 'Var119': 1991,\n",
       " 'Var120': 17799,\n",
       " 'Var121': 18038,\n",
       " 'Var122': 17831,\n",
       " 'Var123': 1792,\n",
       " 'Var124': 17736,\n",
       " 'Var125': 1976,\n",
       " 'Var126': 5044,\n",
       " 'Var127': 17922,\n",
       " 'Var128': 17922,\n",
       " 'Var129': 18038,\n",
       " 'Var130': 17832,\n",
       " 'Var131': 18038,\n",
       " 'Var132': 1792,\n",
       " 'Var133': 1792,\n",
       " 'Var134': 1792,\n",
       " 'Var135': 17736,\n",
       " 'Var136': 18041,\n",
       " 'Var137': 18038,\n",
       " 'Var138': 17736,\n",
       " 'Var139': 17799,\n",
       " 'Var140': 1976,\n",
       " 'Var141': 18299,\n",
       " 'Var142': 18038,\n",
       " 'Var143': 1792,\n",
       " 'Var144': 1991,\n",
       " 'Var145': 17736,\n",
       " 'Var146': 17799,\n",
       " 'Var147': 17799,\n",
       " 'Var148': 17799,\n",
       " 'Var149': 2616,\n",
       " 'Var150': 17736,\n",
       " 'Var151': 18010,\n",
       " 'Var152': 17736,\n",
       " 'Var153': 1792,\n",
       " 'Var154': 18038,\n",
       " 'Var155': 17736,\n",
       " 'Var156': 18041,\n",
       " 'Var157': 17911,\n",
       " 'Var158': 18009,\n",
       " 'Var159': 17831,\n",
       " 'Var160': 1792,\n",
       " 'Var161': 17736,\n",
       " 'Var162': 17831,\n",
       " 'Var163': 1792,\n",
       " 'Var164': 17736,\n",
       " 'Var165': 18009,\n",
       " 'Var166': 17799,\n",
       " 'Var167': 18299,\n",
       " 'Var168': 18038,\n",
       " 'Var169': 18299,\n",
       " 'Var170': 17831,\n",
       " 'Var171': 17922,\n",
       " 'Var172': 17799,\n",
       " 'Var173': 1792,\n",
       " 'Var174': 17736,\n",
       " 'Var175': 18299,\n",
       " 'Var176': 17832,\n",
       " 'Var177': 17831,\n",
       " 'Var178': 18055,\n",
       " 'Var179': 17736,\n",
       " 'Var180': 18038,\n",
       " 'Var181': 1792,\n",
       " 'Var182': 17736,\n",
       " 'Var183': 17831,\n",
       " 'Var184': 17831,\n",
       " 'Var185': 18299,\n",
       " 'Var186': 18038,\n",
       " 'Var187': 18038,\n",
       " 'Var188': 17831,\n",
       " 'Var189': 10618,\n",
       " 'Var190': 18195,\n",
       " 'Var191': 17922,\n",
       " 'Var192': 124,\n",
       " 'Var193': 0,\n",
       " 'Var194': 13660,\n",
       " 'Var195': 0,\n",
       " 'Var196': 0,\n",
       " 'Var197': 55,\n",
       " 'Var198': 0,\n",
       " 'Var199': 2,\n",
       " 'Var200': 9305,\n",
       " 'Var201': 13660,\n",
       " 'Var202': 1,\n",
       " 'Var203': 55,\n",
       " 'Var204': 0,\n",
       " 'Var205': 714,\n",
       " 'Var206': 1991,\n",
       " 'Var207': 0,\n",
       " 'Var208': 55,\n",
       " 'Var209': 18299,\n",
       " 'Var210': 0,\n",
       " 'Var211': 0,\n",
       " 'Var212': 0,\n",
       " 'Var213': 17911,\n",
       " 'Var214': 9305,\n",
       " 'Var215': 18041,\n",
       " 'Var216': 1,\n",
       " 'Var217': 270,\n",
       " 'Var218': 270,\n",
       " 'Var219': 1883,\n",
       " 'Var220': 1,\n",
       " 'Var221': 1,\n",
       " 'Var222': 1,\n",
       " 'Var223': 1883,\n",
       " 'Var224': 17990,\n",
       " 'Var225': 9572,\n",
       " 'Var226': 1,\n",
       " 'Var227': 1,\n",
       " 'Var228': 1,\n",
       " 'Var229': 10366,\n",
       " 'Var230': 18299,\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null in features\n",
    "dict_nan = {name: np.sum(data[name].isnull()) for name in data.columns}\n",
    "dict_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bde9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0    16921\n",
      " 1.0     1377\n",
      "Name: labels, dtype: int64\n",
      "[-1.  1. nan]\n"
     ]
    }
   ],
   "source": [
    "# check disbalance in classes\n",
    "print(data['labels'].value_counts())\n",
    "print(data['labels'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c1b740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels'].replace(-1, 0, inplace=True)\n",
    "data.dropna(subset=['labels'], inplace=True)\n",
    "labels = data['labels']\n",
    "data = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad50a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # balance class by undersampling\n",
    "# count_add = int((len(labels[labels == 0]) - len(labels[labels == 1]))*0.7)\n",
    "# index_for_balance = labels[labels == 1].index\n",
    "# add_index = np.random.choice(index_for_balance, size = count_add)\n",
    "# data_add = data.iloc[add_index]\n",
    "# labels_add = labels.iloc[add_index]\n",
    "\n",
    "# data = pd.concat([data, data_add])\n",
    "# labels = pd.concat([labels, labels_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8967ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # balanced\n",
    "# count_add = int((len(labels[labels == 0]) - len(labels[labels == 1]))*0.7)\n",
    "# index_for_balance = labels[labels == 0].index\n",
    "# drop_index = np.random.choice(index_for_balance, size = count_add, replace=False)\n",
    "\n",
    "# data.drop(index=drop_index, inplace=True)\n",
    "# labels.drop(index=drop_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482b848f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    16921\n",
       "1.0     1377\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab0b3e",
   "metadata": {},
   "source": [
    "# Simple preprocessing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54328f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feture with null more half of dataset\n",
    "def check_feat_without(data, columns, threshold = 0):\n",
    "    flag_nan_col = [np.sum(data[name].isnull()) < threshold for name in columns]\n",
    "    return columns[flag_nan_col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b02b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "numeric_col = data.columns[1:190]\n",
    "cat_col = data.columns[190:]\n",
    "print(len(numeric_col))\n",
    "print(len(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f44086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "right_numeric_column = check_feat_without(data, numeric_col, threshold = len(data)//2)\n",
    "right_cat_column = check_feat_without(data, cat_col, threshold = len(data)//2)\n",
    "print(len(right_numeric_column))\n",
    "print(len(right_cat_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de421553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[np.union1d(right_numeric_column, right_cat_column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd15f9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var192: 326\n",
      "Var193: 44\n",
      "Var195: 21\n",
      "Var196: 4\n",
      "Var197: 207\n",
      "Var198: 2721\n",
      "Var199: 2639\n",
      "Var202: 4673\n",
      "Var203: 4\n",
      "Var204: 100\n",
      "Var205: 4\n",
      "Var206: 22\n",
      "Var207: 12\n",
      "Var208: 3\n",
      "Var210: 6\n",
      "Var211: 2\n",
      "Var212: 71\n",
      "Var216: 1247\n",
      "Var217: 7944\n",
      "Var218: 3\n",
      "Var219: 20\n",
      "Var220: 2721\n",
      "Var221: 7\n",
      "Var222: 2721\n",
      "Var223: 5\n",
      "Var226: 23\n",
      "Var227: 7\n",
      "Var228: 29\n"
     ]
    }
   ],
   "source": [
    "# check unique in cat feat\n",
    "for cur_cat in right_cat_column:\n",
    "    count_uniq = len(data[cur_cat].unique())\n",
    "    print(f'{cur_cat}: {count_uniq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f09f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var6: 1039\n",
      "Var7: 7\n",
      "Var13: 1877\n",
      "Var21: 498\n",
      "Var22: 498\n",
      "Var24: 63\n",
      "Var25: 190\n",
      "Var28: 2513\n",
      "Var35: 10\n",
      "Var38: 11908\n",
      "Var44: 6\n",
      "Var57: 14013\n",
      "Var65: 13\n",
      "Var72: 9\n",
      "Var73: 129\n",
      "Var74: 284\n",
      "Var76: 11377\n",
      "Var78: 13\n",
      "Var81: 15952\n",
      "Var83: 130\n",
      "Var85: 109\n",
      "Var94: 8571\n",
      "Var109: 149\n",
      "Var112: 158\n",
      "Var113: 17900\n",
      "Var119: 1003\n",
      "Var123: 191\n",
      "Var125: 6217\n",
      "Var126: 52\n",
      "Var132: 18\n",
      "Var133: 14165\n",
      "Var134: 12639\n",
      "Var140: 1859\n",
      "Var143: 5\n",
      "Var144: 11\n",
      "Var149: 7524\n",
      "Var153: 14567\n",
      "Var160: 273\n",
      "Var163: 9049\n",
      "Var173: 4\n",
      "Var181: 7\n"
     ]
    }
   ],
   "source": [
    "# check unique in num feat\n",
    "for cur_num in right_numeric_column:\n",
    "    count_uniq = len(data[cur_num].unique())\n",
    "    print(f'{cur_num}: {count_uniq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "098c5e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan,  2.,  4.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Var173'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bf470",
   "metadata": {},
   "source": [
    "Cat boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "988ab5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_boost, test_data_boost, train_label_boost, test_label_boost = train_test_split(data, labels,\n",
    "                                                                                         test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90a8cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_boost.fillna('NaN',inplace=True)\n",
    "test_data_boost.fillna('NaN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32363584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations= 200, random_seed=0, eval_metric='F1', loss_function='Logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21b4448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ebb764d2cb4bea90819345ec55cb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2658e054e80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_boost, train_label_boost,\n",
    "          cat_features=list(right_cat_column),\n",
    "          eval_set =(test_data_boost, test_label_boost),\n",
    "          verbose=False,\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f75bbe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6071ebeec7394a9ab092398593ad2dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.006269592476\n",
      "bestIteration = 133\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.006269592476\n",
      "bestIteration = 190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_params = model.get_params()\n",
    "cv_data = cv(\n",
    "    Pool(train_data_boost, train_label_boost, cat_features=list(right_cat_column)),\n",
    "    cv_params,\n",
    "    plot=True,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af65b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(train_data_boost, train_label_boost, cat_features=list(right_cat_column))\n",
    "test_pool = Pool(test_data_boost, test_label_boost, cat_features=list(right_cat_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab2380",
   "metadata": {},
   "source": [
    "Early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a824dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_params = model.get_params().copy()\n",
    "early_stop_params.update({\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "    'iterations': 500\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d821a78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeb96ce9518406ea50659679502f6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x265bc9ec940>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_model = CatBoostClassifier(**early_stop_params)\n",
    "early_stop_model.fit(train_pool,\n",
    "          eval_set =test_pool,\n",
    "          verbose=False,\n",
    "          plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64927f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var126: 29.912216159079684\n",
      "Var218: 6.111748930487022\n",
      "Var199: 4.963949023551802\n",
      "Var205: 4.670981630285442\n",
      "Var74: 4.082971510804079\n",
      "Var113: 3.577766056353002\n",
      "Var212: 3.088485609988301\n",
      "Var210: 3.0473900750053375\n",
      "Var73: 2.9284793659259303\n",
      "Var216: 2.7197968536519004\n",
      "Var81: 2.5555615936107365\n",
      "Var28: 2.1318593572360722\n",
      "Var125: 1.8833603734579378\n",
      "Var207: 1.7742199355183077\n",
      "Var206: 1.710340682269077\n",
      "Var228: 1.6810619443240038\n",
      "Var222: 1.5649881615789072\n",
      "Var134: 1.5479331797457034\n",
      "Var132: 1.4677953362201985\n",
      "Var193: 1.4205533859013337\n",
      "Var13: 1.3382571132390741\n",
      "Var195: 1.1366948234548448\n",
      "Var197: 1.1070104365243614\n",
      "Var7: 0.9514054350136616\n",
      "Var227: 0.8184792407687856\n",
      "Var211: 0.7484499585608848\n",
      "Var226: 0.7355563694954477\n",
      "Var44: 0.7347058792195502\n",
      "Var204: 0.7267037261588836\n",
      "Var203: 0.668658969241591\n",
      "Var85: 0.5660668112792898\n",
      "Var219: 0.5424888923407611\n",
      "Var119: 0.541649392201261\n",
      "Var192: 0.5171015081083691\n",
      "Var6: 0.4911723148986432\n",
      "Var25: 0.42781279445965215\n",
      "Var24: 0.35414938425790055\n",
      "Var160: 0.3439368939362692\n",
      "Var38: 0.34186092112206684\n",
      "Var173: 0.3373888074583691\n",
      "Var76: 0.31029154276320914\n",
      "Var196: 0.3080574262076558\n",
      "Var22: 0.27896720149361964\n",
      "Var223: 0.2693709390130766\n",
      "Var94: 0.2610553812620581\n",
      "Var143: 0.2496719427956414\n",
      "Var163: 0.2358282647752492\n",
      "Var57: 0.23577405711089355\n",
      "Var133: 0.21973740855925672\n",
      "Var208: 0.20950467782714877\n",
      "Var21: 0.19744609059836424\n",
      "Var153: 0.16649007377977115\n",
      "Var221: 0.16408587309937284\n",
      "Var144: 0.15636909794131992\n",
      "Var123: 0.12348971640439456\n",
      "Var83: 0.09364419786139883\n",
      "Var109: 0.0705079725360112\n",
      "Var198: 0.05380207263802821\n",
      "Var65: 0.0425387273807278\n",
      "Var78: 0.028357605226665337\n",
      "Var220: 0.02713126233231878\n",
      "Var35: 0.02686963165930636\n",
      "Var72: 0.0\n",
      "Var217: 0.0\n",
      "Var202: 0.0\n",
      "Var181: 0.0\n",
      "Var149: 0.0\n",
      "Var140: 0.0\n",
      "Var112: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importances = early_stop_model.get_feature_importance(train_pool)\n",
    "feature_names = train_data_boost.columns\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print('{}: {}'.format(name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699ff33",
   "metadata": {},
   "source": [
    "Find optimal parameters model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2b7d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_obj(params):\n",
    "    model = CatBoostClassifier(\n",
    "                                l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "                                learning_rate=params['learning_rate'],\n",
    "                                depth = int(params['depth']),\n",
    "                                iterations=500,\n",
    "                                eval_metric='F1',\n",
    "                                loss_function='Logloss',\n",
    "                                random_seed=42,\n",
    "                                verbose=False\n",
    "                              )\n",
    "    cv_calc = cv( train_pool,\n",
    "                 model.get_params(),\n",
    "                 verbose=False)\n",
    "    best_metrics = np.max(cv_data['test-F1-mean'])\n",
    "    return 1 - best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe67d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1126760563\n",
      "bestIteration = 378\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07329842932\n",
      "bestIteration = 466\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07669616519\n",
      "bestIteration = 105\n",
      "\n",
      "  2%|▉                                                | 1/50 [00:49<40:13, 49.27s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1270718232\n",
      "bestIteration = 226\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08287292818\n",
      "bestIteration = 414\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07492795389\n",
      "bestIteration = 353\n",
      "\n",
      "  4%|█▉                                               | 2/50 [01:38<39:30, 49.39s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06976744186\n",
      "bestIteration = 264\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04093567251\n",
      "bestIteration = 389\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.0650887574\n",
      "bestIteration = 362\n",
      "\n",
      "  6%|██▉                                              | 3/50 [02:02<29:22, 37.49s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07079646018\n",
      "bestIteration = 179\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04719764012\n",
      "bestIteration = 403\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06547619048\n",
      "bestIteration = 263\n",
      "\n",
      "  8%|███▉                                             | 4/50 [03:24<42:17, 55.16s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07344632768\n",
      "bestIteration = 485\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.0782122905\n",
      "bestIteration = 187\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1016949153\n",
      "bestIteration = 134\n",
      "\n",
      " 10%|████▉                                            | 5/50 [04:46<48:47, 65.06s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.04307692308\n",
      "bestIteration = 135\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.01242236025\n",
      "bestIteration = 198\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.01246105919\n",
      "bestIteration = 111\n",
      "\n",
      " 12%|█████▌                                        | 6/50 [09:23<1:40:24, 136.93s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.09065155807\n",
      "bestIteration = 493\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08139534884\n",
      "bestIteration = 150\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06395348837\n",
      "bestIteration = 449\n",
      "\n",
      " 14%|██████▍                                       | 7/50 [10:46<1:25:31, 119.33s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08187134503\n",
      "bestIteration = 204\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07471264368\n",
      "bestIteration = 136\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.09221902017\n",
      "bestIteration = 297\n",
      "\n",
      " 16%|███████▎                                      | 8/50 [12:09<1:15:32, 107.92s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.04819277108\n",
      "bestIteration = 417\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03012048193\n",
      "bestIteration = 442\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05389221557\n",
      "bestIteration = 489\n",
      "\n",
      " 18%|████████▍                                      | 9/50 [12:58<1:01:05, 89.39s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.09444444444\n",
      "bestIteration = 498\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07262569832\n",
      "bestIteration = 488\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06489675516\n",
      "bestIteration = 333\n",
      "\n",
      " 20%|█████████▌                                      | 10/50 [13:47<51:16, 76.91s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06358381503\n",
      "bestIteration = 488\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06837606838\n",
      "bestIteration = 495\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.04761904762\n",
      "bestIteration = 368\n",
      "\n",
      " 22%|██████████▌                                     | 11/50 [14:11<39:23, 60.60s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08069164265\n",
      "bestIteration = 496\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.05681818182\n",
      "bestIteration = 481\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05847953216\n",
      "bestIteration = 426\n",
      "\n",
      " 24%|███████████▌                                    | 12/50 [15:00<36:12, 57.16s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07580174927\n",
      "bestIteration = 155\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04804804805\n",
      "bestIteration = 105\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.03658536585\n",
      "bestIteration = 75\n",
      "\n",
      " 26%|████████████▍                                   | 13/50 [17:28<52:14, 84.72s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1144414169\n",
      "bestIteration = 233\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08465608466\n",
      "bestIteration = 174\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.09444444444\n",
      "bestIteration = 371\n",
      "\n",
      " 28%|█████████████▍                                  | 14/50 [18:51<50:30, 84.18s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.09523809524\n",
      "bestIteration = 498\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07027027027\n",
      "bestIteration = 490\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06896551724\n",
      "bestIteration = 433\n",
      "\n",
      " 30%|██████████████▍                                 | 15/50 [19:15<38:27, 65.92s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06936416185\n",
      "bestIteration = 317\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04692082111\n",
      "bestIteration = 485\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05389221557\n",
      "bestIteration = 358\n",
      "\n",
      " 32%|███████████████▎                                | 16/50 [20:03<34:23, 60.70s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08045977011\n",
      "bestIteration = 453\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08913649025\n",
      "bestIteration = 225\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05813953488\n",
      "bestIteration = 457\n",
      "\n",
      " 34%|████████████████▎                               | 17/50 [20:53<31:30, 57.29s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1002785515\n",
      "bestIteration = 449\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07936507937\n",
      "bestIteration = 389\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1032608696\n",
      "bestIteration = 300\n",
      "\n",
      " 36%|█████████████████▎                              | 18/50 [22:16<34:42, 65.07s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.03012048193\n",
      "bestIteration = 430\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03058103976\n",
      "bestIteration = 235\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.0421686747\n",
      "bestIteration = 464\n",
      "\n",
      " 38%|██████████████████▏                             | 19/50 [22:40<27:13, 52.68s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08045977011\n",
      "bestIteration = 135\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04105571848\n",
      "bestIteration = 108\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05917159763\n",
      "bestIteration = 60\n",
      "\n",
      " 40%|███████████████████▏                            | 20/50 [25:08<40:47, 81.57s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08474576271\n",
      "bestIteration = 45\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07344632768\n",
      "bestIteration = 222\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05681818182\n",
      "bestIteration = 74\n",
      "\n",
      " 42%|███████████████████▋                           | 21/50 [27:39<49:26, 102.29s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.02461538462\n",
      "bestIteration = 390\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.00625\n",
      "bestIteration = 309\n",
      "\n",
      " 44%|█████████████████████                           | 22/50 [28:03<36:42, 78.67s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06395348837\n",
      "bestIteration = 144\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.0412979351\n",
      "bestIteration = 43\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06451612903\n",
      "bestIteration = 81\n",
      "\n",
      " 46%|██████████████████████                          | 23/50 [30:32<44:56, 99.88s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.0125\n",
      "bestIteration = 326\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.006269592476\n",
      "bestIteration = 396\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      " 48%|██████████████████████▌                        | 24/50 [34:18<59:37, 137.60s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0\n",
      "bestIteration = 0\n",
      "\n",
      " 50%|███████████████████████▌                       | 25/50 [34:39<42:47, 102.71s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.04705882353\n",
      "bestIteration = 28\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08398950131\n",
      "bestIteration = 124\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1160220994\n",
      "bestIteration = 101\n",
      "\n",
      " 52%|████████████████████████▍                      | 26/50 [37:09<46:43, 116.83s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.03067484663\n",
      "bestIteration = 135\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03076923077\n",
      "bestIteration = 68\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.02469135802\n",
      "bestIteration = 76\n",
      "\n",
      " 54%|████████████████████████▎                    | 27/50 [41:45<1:03:10, 164.80s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.03067484663\n",
      "bestIteration = 463\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.01863354037\n",
      "bestIteration = 424\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.01246105919\n",
      "bestIteration = 384\n",
      "\n",
      " 56%|██████████████████████████▎                    | 28/50 [42:08<44:49, 122.26s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07588075881\n",
      "bestIteration = 123\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06214689266\n",
      "bestIteration = 237\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.08\n",
      "bestIteration = 80\n",
      "\n",
      " 58%|███████████████████████████▎                   | 29/50 [44:37<45:35, 130.24s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.01863354037\n",
      "bestIteration = 333\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.0245398773\n",
      "bestIteration = 100\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.02461538462\n",
      "bestIteration = 37\n",
      "\n",
      " 60%|████████████████████████████▏                  | 30/50 [49:12<57:50, 173.51s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.0421686747\n",
      "bestIteration = 493\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03625377644\n",
      "bestIteration = 477\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.04268292683\n",
      "bestIteration = 412\n",
      "\n",
      " 62%|█████████████████████████████▏                 | 31/50 [50:00<43:02, 135.91s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07799442897\n",
      "bestIteration = 171\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07843137255\n",
      "bestIteration = 71\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06976744186\n",
      "bestIteration = 439\n",
      "\n",
      " 64%|██████████████████████████████                 | 32/50 [52:29<41:58, 139.90s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07558139535\n",
      "bestIteration = 478\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.05247813411\n",
      "bestIteration = 262\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.04804804805\n",
      "bestIteration = 318\n",
      "\n",
      " 66%|███████████████████████████████                | 33/50 [53:20<32:02, 113.10s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08595988539\n",
      "bestIteration = 479\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.05113636364\n",
      "bestIteration = 348\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.06916426513\n",
      "bestIteration = 376\n",
      "\n",
      " 68%|████████████████████████████████▋               | 34/50 [54:10<25:07, 94.22s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08403361345\n",
      "bestIteration = 362\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08970976253\n",
      "bestIteration = 130\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.0773480663\n",
      "bestIteration = 248\n",
      "\n",
      " 70%|█████████████████████████████████▌              | 35/50 [55:33<22:44, 90.95s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1173184358\n",
      "bestIteration = 460\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06857142857\n",
      "bestIteration = 174\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.09039548023\n",
      "bestIteration = 340\n",
      "\n",
      " 72%|██████████████████████████████████▌             | 36/50 [56:56<20:39, 88.55s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08498583569\n",
      "bestIteration = 93\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04610951009\n",
      "bestIteration = 36\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07558139535\n",
      "bestIteration = 279\n",
      "\n",
      " 74%|██████████████████████████████████▊            | 37/50 [59:27<23:12, 107.15s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.03658536585\n",
      "bestIteration = 23\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.05373134328\n",
      "bestIteration = 102\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05917159763\n",
      "bestIteration = 61\n",
      "\n",
      " 76%|██████████████████████████████████▏          | 38/50 [1:04:03<31:33, 157.76s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06798866856\n",
      "bestIteration = 373\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06818181818\n",
      "bestIteration = 250\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.08645533141\n",
      "bestIteration = 368\n",
      "\n",
      " 78%|███████████████████████████████████          | 39/50 [1:04:26<21:30, 117.35s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.05917159763\n",
      "bestIteration = 453\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03560830861\n",
      "bestIteration = 286\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.04229607251\n",
      "bestIteration = 254\n",
      "\n",
      " 80%|████████████████████████████████████▊         | 40/50 [1:04:49<14:51, 89.17s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07038123167\n",
      "bestIteration = 73\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06741573034\n",
      "bestIteration = 104\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1135135135\n",
      "bestIteration = 261\n",
      "\n",
      " 82%|█████████████████████████████████████▋        | 41/50 [1:06:12<13:06, 87.40s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08547008547\n",
      "bestIteration = 454\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08767123288\n",
      "bestIteration = 308\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07100591716\n",
      "bestIteration = 81\n",
      "\n",
      " 84%|██████████████████████████████████████▋       | 42/50 [1:07:36<11:30, 86.32s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.04848484848\n",
      "bestIteration = 482\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04804804805\n",
      "bestIteration = 423\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.03692307692\n",
      "bestIteration = 354\n",
      "\n",
      " 86%|███████████████████████████████████████▌      | 43/50 [1:08:24<08:43, 74.76s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.05438066465\n",
      "bestIteration = 119\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03095975232\n",
      "bestIteration = 94\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.03076923077\n",
      "bestIteration = 132\n",
      "\n",
      " 88%|███████████████████████████████████████▌     | 44/50 [1:13:04<13:37, 136.26s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.06976744186\n",
      "bestIteration = 447\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.04597701149\n",
      "bestIteration = 412\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.05970149254\n",
      "bestIteration = 414\n",
      "\n",
      " 90%|████████████████████████████████████████▌    | 45/50 [1:13:27<08:32, 102.48s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.08522727273\n",
      "bestIteration = 439\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.08498583569\n",
      "bestIteration = 354\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.08\n",
      "bestIteration = 499\n",
      "\n",
      " 92%|██████████████████████████████████████████▎   | 46/50 [1:14:17<05:46, 86.53s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.07386363636\n",
      "bestIteration = 196\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.07954545455\n",
      "bestIteration = 103\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.09604519774\n",
      "bestIteration = 86\n",
      "\n",
      " 94%|██████████████████████████████████████████▎  | 47/50 [1:16:45<05:15, 105.23s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1101928375\n",
      "bestIteration = 475\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.112\n",
      "bestIteration = 173\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07799442897\n",
      "bestIteration = 279\n",
      "\n",
      " 96%|████████████████████████████████████████████▏ | 48/50 [1:18:09<03:17, 98.82s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1222222222\n",
      "bestIteration = 308\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.06094182825\n",
      "bestIteration = 299\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.07954545455\n",
      "bestIteration = 364\n",
      "\n",
      " 98%|█████████████████████████████████████████████ | 49/50 [1:18:58<01:23, 83.88s/trial, best loss: 0.9958202716823407]Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.03669724771\n",
      "bestIteration = 468\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.03067484663\n",
      "bestIteration = 348\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.01857585139\n",
      "bestIteration = 67\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 50/50 [1:23:32<00:00, 100.24s/trial, best loss: 0.9958202716823407]\n",
      "{'depth': 4.0, 'l2_leaf_reg': 2.0, 'learning_rate': 0.28614075781169124}\n"
     ]
    }
   ],
   "source": [
    "params_opt = {\n",
    "                'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "                'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "                'depth': hyperopt.hp.quniform('depth', 1, 10,2)\n",
    "                }\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_obj,\n",
    "    space=params_opt,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    #rstate=np.random.RandomState(123)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffb9e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4.0, 'l2_leaf_reg': 2.0, 'learning_rate': 0.28614075781169124}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ba8bda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(\n",
    "                                l2_leaf_reg=int(best['l2_leaf_reg']),\n",
    "                                learning_rate=best['learning_rate'],\n",
    "                                depth = int(best['depth']),\n",
    "                                iterations=100,\n",
    "                                eval_metric='AUC',\n",
    "                                loss_function='Logloss',\n",
    "                                random_seed=42,\n",
    "                                verbose=False,\n",
    "                                use_best_model=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a3867c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e253951f324f888acc8f7606272a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x26580366490>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_pool,\n",
    "               eval_set =test_pool,\n",
    "               verbose=False,\n",
    "               plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a72cb020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b282602428a443da7d33a3bfd4ffbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': [0.5574368803492018,\n",
       "  0.5642532719051911,\n",
       "  0.5752251878971166,\n",
       "  0.6091900591438297,\n",
       "  0.6344525843767923,\n",
       "  0.6551503642485232,\n",
       "  0.7052834192433464,\n",
       "  0.7049012003813808,\n",
       "  0.7097885738441254,\n",
       "  0.7138689115002719,\n",
       "  0.7116950126257924,\n",
       "  0.7120865425440785,\n",
       "  0.713909414595267,\n",
       "  0.7171422133498201,\n",
       "  0.721579397239458,\n",
       "  0.7264884189081483,\n",
       "  0.7285035642723596,\n",
       "  0.7318045665144619,\n",
       "  0.7375983713100284,\n",
       "  0.7375983713100284,\n",
       "  0.7375622909667856,\n",
       "  0.7382948383228181,\n",
       "  0.7393567642961959,\n",
       "  0.7393567642961959,\n",
       "  0.7394417276851224,\n",
       "  0.7404370796058071,\n",
       "  0.7418076670962167,\n",
       "  0.7418104604131129,\n",
       "  0.7421507795216351,\n",
       "  0.7418816899939664,\n",
       "  0.742472942070332,\n",
       "  0.7430800229424428,\n",
       "  0.7424217312605681,\n",
       "  0.7450050838367511,\n",
       "  0.7460444304985512,\n",
       "  0.7462602142287837],\n",
       " 'F1': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.004705882352941177,\n",
       "  0.004705882352941177,\n",
       "  0.009389671361502346,\n",
       "  0.009389671361502346,\n",
       "  0.009389671361502346,\n",
       "  0.009389671361502346,\n",
       "  0.009389671361502346,\n",
       "  0.01405152224824356,\n",
       "  0.01405152224824356,\n",
       "  0.023310023310023312,\n",
       "  0.023310023310023312,\n",
       "  0.023310023310023312,\n",
       "  0.02790697674418605,\n",
       "  0.02790697674418605,\n",
       "  0.023310023310023312,\n",
       "  0.023310023310023312,\n",
       "  0.023310023310023312,\n",
       "  0.018691588785046728,\n",
       "  0.023310023310023312,\n",
       "  0.02777777777777778,\n",
       "  0.03233256351039261,\n",
       "  0.03686635944700461,\n",
       "  0.041284403669724766,\n",
       "  0.041284403669724766,\n",
       "  0.041284403669724766]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.eval_metrics(test_pool, ['AUC','F1'], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa41f7",
   "metadata": {},
   "source": [
    "test competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "579a2fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = pd.read_csv('./data/orange_small_churn_test_data.csv')\n",
    "data_comp = data_comp[np.union1d(right_numeric_column, right_cat_column)]\n",
    "data_comp.fillna('NaN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a4351a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95424737, 0.04575263],\n",
       "       [0.93413736, 0.06586264],\n",
       "       [0.8547482 , 0.1452518 ],\n",
       "       ...,\n",
       "       [0.95957516, 0.04042484],\n",
       "       [0.98051273, 0.01948727],\n",
       "       [0.95504454, 0.04495546]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_probs = best_model.predict_proba(data_comp)\n",
    "predictions_probs[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6cdd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(enumerate(predictions_probs[:,1]), columns=['Id', 'result'])\n",
    "out_df.to_csv('output_df.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067739d6",
   "metadata": {},
   "source": [
    "This method give auc about 0.7, but f1 is so little we need to choice right treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885cea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
